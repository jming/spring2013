\documentclass[11pt]{article}
\usepackage{latexsym}
\usepackage{amssymb,amsmath}
\usepackage[pdftex]{graphicx}
% \usepackage{qtree}

\topmargin = -.75in \textwidth=7in \textheight=9.3in
\oddsidemargin = -.3in \evensidemargin = -.3in

\begin{document}
\begin{center}
\large
CS181 Assignment 3
\end{center}
Joy Ming and Alisa Nguyen (15 March 2013)\\

\section{Problem 1}
\begin{enumerate}
\item The probability that all of the $M$ dimensions of $x - y$ are between $-\epsilon \text{ and } \epsilon$ is
\item The probability of $max_m |x_m - y_m| \leq \epsilon$ is at most $p$
\item If $x$ is any point in $\chi$, and $y$ is a point in $\chi$ drawn randomly from a uniform distribution on $\chi$, then the probabilty that $||x - y|| \leq \epsilon$ is also at most $p$
\item Lowerbound on number $N$ of points needed to guarantee
\item We can conclude that the effectiveness of the hierarchical agglomerativ clustering algorithm in high dimensional spaces
\end{enumerate}

\section{Problem 2}
\begin{enumerate}
\item Given a prior
\item MAP can be considered "more Bayesian" than ML because
\item One advantage the MAP method enjoys over the Ml method
\item The Beta distribution ins the conjugate prior of the Bernoulli
\item Under the ML approach
\end{enumerate}

\section{Problem 3}
\begin{enumerate}
\item The $K$ -means clustering objective is
\item PCA relates to $K$-means
\end{enumerate}

\section{Problem 4}

\end{document}